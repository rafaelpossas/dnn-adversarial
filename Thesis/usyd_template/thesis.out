\BOOKMARK [0][-]{chapter*.2}{Student Plagiarism: Compliance Statement}{}% 1
\BOOKMARK [0][-]{chapter*.4}{Abstract}{}% 2
\BOOKMARK [0][-]{chapter*.6}{Acknowledgements}{}% 3
\BOOKMARK [0][-]{chapter*.6}{List of Figures}{}% 4
\BOOKMARK [0][-]{chapter*.6}{List of Tables}{}% 5
\BOOKMARK [0][-]{chapter.1}{Chapter 1. Introduction}{}% 6
\BOOKMARK [1][-]{section.1.1}{1.1. Motivation}{chapter.1}% 7
\BOOKMARK [1][-]{section.1.2}{1.2. Thesis Structure}{chapter.1}% 8
\BOOKMARK [0][-]{chapter.2}{Chapter 2. Background}{}% 9
\BOOKMARK [1][-]{section.2.1}{2.1. \040\(Shallow\) Neural Networks}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.2}{2.2. Gradient methods and backpropagation}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.3}{2.3. Convolutional neural networks}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.4}{2.4. CNNs feature learning and visualization}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.5}{2.5. CNNs Architectures}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.6}{2.6. CNNs properties}{chapter.2}% 15
\BOOKMARK [0][-]{chapter.3}{Chapter 3. Adversarial attacks, imbalanced learning and domain shift}{}% 16
\BOOKMARK [1][-]{section.3.1}{3.1. Why adversaries exist?}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.2}{3.2. Learning from imbalanced data}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.3}{3.3. Domain shift}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.4}{3.4. Fast gradient sign method - FGSM}{chapter.3}% 20
\BOOKMARK [1][-]{section.3.5}{3.5. Iterative gradient sign method - IGSM}{chapter.3}% 21
\BOOKMARK [1][-]{section.3.6}{3.6. Ascent and descent perturbations}{chapter.3}% 22
\BOOKMARK [0][-]{chapter.4}{Chapter 4. Attacking machine learning systems}{}% 23
\BOOKMARK [1][-]{section.4.1}{4.1. Transferability}{chapter.4}% 24
\BOOKMARK [1][-]{section.4.2}{4.2. Intra-technique transferability}{chapter.4}% 25
\BOOKMARK [1][-]{section.4.3}{4.3. Cross-technique transferability}{chapter.4}% 26
\BOOKMARK [1][-]{section.4.4}{4.4. Black-box Attacks}{chapter.4}% 27
\BOOKMARK [1][-]{section.4.5}{4.5. Unrecognizable Images}{chapter.4}% 28
\BOOKMARK [1][-]{section.4.6}{4.6. Adversarials in the Physical World}{chapter.4}% 29
\BOOKMARK [1][-]{section.4.7}{4.7. Defending Against Adversarial Attacks}{chapter.4}% 30
\BOOKMARK [0][-]{chapter.5}{Chapter 5. Experiment design}{}% 31
\BOOKMARK [1][-]{section.5.1}{5.1. Data domain}{chapter.5}% 32
\BOOKMARK [1][-]{section.5.2}{5.2. The VGG architecture}{chapter.5}% 33
\BOOKMARK [1][-]{section.5.3}{5.3. Overall training process}{chapter.5}% 34
\BOOKMARK [1][-]{section.5.4}{5.4. Perturbation method}{chapter.5}% 35
\BOOKMARK [1][-]{section.5.5}{5.5. Synthetic data imbalance}{chapter.5}% 36
\BOOKMARK [0][-]{chapter.6}{Chapter 6. Results}{}% 37
\BOOKMARK [1][-]{section.6.1}{6.1. Baseline model}{chapter.6}% 38
\BOOKMARK [1][-]{section.6.2}{6.2. Under-sampling and over-sampling models}{chapter.6}% 39
\BOOKMARK [1][-]{section.6.3}{6.3. Transfer learning}{chapter.6}% 40
\BOOKMARK [1][-]{section.6.4}{6.4. Overlapping distributions}{chapter.6}% 41
\BOOKMARK [0][-]{chapter.7}{Chapter 7. Conclusions and Future work}{}% 42
\BOOKMARK [0][-]{chapter*.8}{Bibliography}{}% 43
