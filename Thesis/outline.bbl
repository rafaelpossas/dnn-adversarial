% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{goodfellow2014}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy, ``Explaining and harnessing
  adversarial examples,'' \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{papernot2016}
N.~Papernot, P.~McDaniel, I.~Goodfellow, S.~Jha, Z.~Berkay~Celik, and A.~Swami,
  ``Practical black-box attacks against deep learning systems using adversarial
  examples,'' \emph{arXiv preprint arXiv:1602.02697}, 2016.

\bibitem{nguyen2015}
A.~Nguyen, J.~Yosinski, and J.~Clune, ``Deep neural networks are easily fooled:
  High confidence predictions for unrecognizable images,'' in \emph{2015 IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2015, pp. 427--436.

\bibitem{papernot2016transf}
N.~Papernot, P.~McDaniel, and I.~Goodfellow, ``Transferability in machine
  learning: from phenomena to black-box attacks using adversarial samples,''
  \emph{arXiv preprint arXiv:1605.07277}, 2016.

\bibitem{billovits}
C.~Billovits, M.~Eric, and N.~Agarwala, ``Hitting depth: Investigating
  robustness to adversarial examples in deep convolutional neural networks.''

\end{thebibliography}
