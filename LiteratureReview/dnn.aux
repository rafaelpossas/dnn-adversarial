\relax 
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{billovits}
\citation{goodfellow2014}
\citation{nielsen2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Key Concepts}{1}}
\newlabel{sec:key_concepts}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Neural Networks}{1}}
\newlabel{subsec:neural_deep}{{2.1}{1}}
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{nielsen2016}
\citation{nielsen2016}
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{nielsen2016}
\citation{goodfellow2016_book}
\citation{nielsen2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple perceptron model}}{2}}
\newlabel{fig:perceptron}{{1}{2}}
\citation{nielsen2016}
\citation{goodfellow2014}
\citation{nielsen2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Output change with regards to layer(s) weight change \cite  {nielsen2016}}}{3}}
\newlabel{fig:net_change}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Gradient Descent}{3}}
\newlabel{subsec:neural_deep}{{2.2}{3}}
\citation{nielsen2016}
\citation{nielsen2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gradient calculation representation \cite  {nielsen2016}}}{4}}
\newlabel{fig:net_change}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Backpropagation}{4}}
\newlabel{subsec:backprop}{{2.3}{4}}
\citation{nielsen2016}
\citation{nielsen2016}
\citation{nielsen2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Learning Slowdown and the Cross-Entropy Cost Function}{5}}
\newlabel{subsec:cross_entropy}{{2.4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sigmoid function Shape}}{5}}
\newlabel{fig:sigmoid}{{4}{5}}
\citation{goodfellow2016_book}
\citation{szegedy2013}
\citation{gu2014}
\citation{szegedy2013}
\citation{szegedy2013}
\citation{goodfellow2014}
\citation{szegedy2013}
\citation{szegedy2013}
\citation{gu2014}
\citation{szegedy2013}
\citation{goodfellow2014}
\@writefile{toc}{\contentsline {section}{\numberline {3}Neural Networks Properties}{6}}
\newlabel{sec: nn_props}{{3}{6}}
\citation{nguyen2015}
\citation{gu2014}
\citation{krizhevsky2012}
\citation{szegedy2013}
\citation{goodfellow2014}
\citation{goodfellow2016}
\citation{dalvi2004}
\citation{goodfellow2014}
\@writefile{toc}{\contentsline {section}{\numberline {4}Adversarial Examples}{7}}
\newlabel{sec: adversarial}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Fast Gradient Sign}{7}}
\newlabel{subsec:fast_gradient}{{4.1}{7}}
\bibstyle{IEEEtran}
\bibdata{ref}
\bibcite{nielsen2016}{1}
\bibcite{goodfellow2016_book}{2}
\bibcite{billovits}{3}
\bibcite{goodfellow2014}{4}
\bibcite{szegedy2013}{5}
\bibcite{gu2014}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Rubbish Class}{8}}
\newlabel{subsec:rubbish}{{4.2}{8}}
\bibcite{nguyen2015}{7}
\bibcite{krizhevsky2012}{8}
\bibcite{goodfellow2016}{9}
\bibcite{dalvi2004}{10}
